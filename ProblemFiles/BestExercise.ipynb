{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#load the preprocessed data\n",
    "#the email matrix that has '1' for a presentation of a word, '0' for not.\n",
    "email_data = np.load('email_data.npz')\n",
    "email_data = email_data['arr_0']\n",
    "#the label of emails\n",
    "email_class = np.load('email_class.npy')\n",
    "\n",
    "#print this two to see the words that are contianed in spam email and ham email\n",
    "#all the spam words in a list\n",
    "spam_word = open(\"spamword_list.txt\",\"r\").readlines()\n",
    "#all the ham words in a list\n",
    "ham_word = open(\"hamword_list.txt\", \"r\").readlines()\n",
    "\n",
    "#visuallize the original data\n",
    "data = pd.read_csv(\"spam_ham.csv\",encoding='latin-1')\n",
    "data = data.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "data = data.rename(columns={\"v1\":\"label\", \"v2\":\"text\"})\n",
    "data['spam:-1_ham:1'] = data['label'].map( {'spam': -1, 'ham': 1} ).astype(int)\n",
    "data['length'] = data['text'].apply(len)\n",
    "data_ham  = data[data['spam:-1_ham:1'] == 1].copy()\n",
    "data_spam = data[data['spam:-1_ham:1'] == -1].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to see content\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to see content\n",
    "#print(spam_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to see content\n",
    "#print(ham_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = email_data\n",
    "d = email_class\n",
    "N = len(email_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint: find the sum of inidicator function\n",
    "def sum_indicator(A, w, d):\n",
    "    v = 0\n",
    "    \n",
    "    #########################\n",
    "    #complete your code here#\n",
    "    #########################\n",
    "    \n",
    "    for i in range(len(d)): #hint: calculate the sum of all indicator function according to content of video 5.7\n",
    "        temp = ? \n",
    "        v+=temp # sum step\n",
    "        \n",
    "    return v.reshape(A.shape[1], -1)\n",
    "\n",
    "# implement a gradient descent method to approach W, look at video 5.7 for formula\n",
    "def sub_gradientdescent(A,d,tau,lam, w_init,it, tol):\n",
    "    W = np.zeros((w_init.shape[0], it+1)) #store all steps\n",
    "    W[:,[0]] = w_init\n",
    "    for k in range(it): #hint: in max iteration, do gradiant descent by using indicator function.\n",
    "        \n",
    "        #########################\n",
    "        #complete your code here#\n",
    "        #########################\n",
    "        \n",
    "        W[:, [k+1]] = ? \n",
    "        if(?):#hint: if meet the tol, directly return the best w\n",
    "            return W[:, [k+1]]\n",
    "            \n",
    "    return W[:,[it]]\n",
    "\n",
    "#implementation begins\n",
    "def my_svm(A_train, d_train, lamda):\n",
    "    w_init = np.zeros((A_train.shape[1], 1))\n",
    "    \n",
    "    tol = 10**(-3)\n",
    "    max_iter = 100\n",
    "    tau = 0.01\n",
    "    #########################\n",
    "    #complete your code here#\n",
    "    #########################\n",
    "    w_best = sub_gradientdescent(?) \n",
    "    err_cnt = ? #calculate the err count to see performance\n",
    "    print('best W is: \\n', w_best, '\\n with error count: ', err_cnt)\n",
    "    \n",
    "    return w_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamda_arr = np.logspace(1, -3, num = 5)\n",
    "#choose lamda\n",
    "A_choose_lam = A[0:500, :]\n",
    "d_choose_lam = d[0:500, 0]\n",
    "w_init = np.zeros((A_choose_lam.shape[1], 1))\n",
    "tol = 10**(-3)\n",
    "max_iter = 100\n",
    "tau = 0.01\n",
    "best_lam_index = 0\n",
    "least_err_cnt = len(d_choose_lam)\n",
    "w_opt =  np.zeros((A_choose_lam.shape[1], 1))#the w that corresponding to best lamda\n",
    "for j in range(len(lamda_arr)):\n",
    "    \n",
    "    #########################\n",
    "    #complete your code here#\n",
    "    #########################\n",
    "\n",
    "print('best lamda:', lamda_arr[best_lam_index], '\\n')\n",
    "#use it in later training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each as a validation set for once, other as training\n",
    "fold = [[1,550],[551,1100],[1101,1650],[1651,2200],[2201,2750],[3301,3850],[4401,4950],[4951,5500],[5501,5571]]\n",
    "lamda = lamda_arr[best_lam_index]\n",
    "w_opt = np.zeros((9431, 1))\n",
    "#abandon last 70 small set\n",
    "fold.pop(len(fold)-1)\n",
    "least_err_cnt = len(d_vali);\n",
    "\n",
    "for i in range (len(fold) - 1): \n",
    "    vali_ind = np.arange(fold[i][0]-1, fold[i][1])\n",
    "    training_ind = list(set(range(5500))-set(vali_ind))\n",
    "    A_train = A[training_ind, :]\n",
    "    d_train = d[training_ind, 0]\n",
    "    A_vali =  A[vali_ind, :]\n",
    "    d_vali = d[vali_ind, 0]\n",
    "    w_opt = np.zeros((9431, 1))\n",
    "    w_best = np.zeros((9431, 1))\n",
    "    err_cnt = 0\n",
    "    \n",
    "    #########################\n",
    "    #complete your code here#\n",
    "    #########################\n",
    "\n",
    "print('BEST W: ', w_opt)\n",
    "print('LEAST ERROR IN 550 DATA:', least_err_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel method using sklearn\n",
    "import sklearn.svm as svm\n",
    "#try with ? mark value to see effect\n",
    "\n",
    "#linear kernel\n",
    "# C is the penalty parameter of the error term. It controls the trade off\n",
    "#    between smooth decision boundary and classifying the training points correctly.\n",
    "\n",
    "advanced_svm = svm.SVC(C = ?, kernel = 'linear')\n",
    "advanced_svm.fit(A[], d[].ravel()) #choose range of data to train\n",
    "advanced_svm.score(A[], d[]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian/RBF kernel\n",
    "# gamma is a parameter for non linear hyperplanes. The higher the gamma value it tries to exactly fit the training data set\n",
    "# C is the penalty parameter of the error term. It controls the trade off\n",
    "#    between smooth decision boundary and classifying the training points correctly.\n",
    "\n",
    "advanced_svm = svm.SVC(C = ?, kernel = 'rbf', gamma = ?)\n",
    "advanced_svm.fit(A[], d[].ravel())#choose range of data to train\n",
    "advanced_svm.score(A[], d[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polynominal kernal\n",
    "# gamma is a parameter for non linear hyperplanes. The higher the gamma value it tries to exactly fit the training data set\n",
    "# C is the penalty parameter of the error term. It controls the trade off\n",
    "#    between smooth decision boundary and classifying the training points correctly.\n",
    "# degree is a parameter used when kernel is set to ‘poly’.\n",
    "#    It’s basically the degree of the polynomial used to find the hyperplane to split the data.\n",
    "\n",
    "advanced_svm = svm.SVC(C = ?, kernel = 'poly', gamma = ?, degree = ?)\n",
    "advanced_svm.fit(A[], d[].ravel())#choose range of data to train\n",
    "advanced_svm.score(A[], d[])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
